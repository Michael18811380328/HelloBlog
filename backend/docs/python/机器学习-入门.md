谈谈机器学习如何入门，主要分为原理入门，编程理解，实战应用，三个步骤。

### 首先三点比较重要

第一、反对上来就给你推荐 python，sklearn，pandas 之类的，不是培训班广告就是忽悠人。这些东西不适合入门，只适合调包侠。

第二、 不推荐任何国内的非知名大学的视频教程。大部分的东西不是抄就是质量太差，有吴恩达的公开课不看去买网课，留着钱买个大鸡腿吃不好吗。

第三、不推荐任何上来就是各种花里胡哨的实战项目，这也是培训班的套路，抓住人就想心急吃热豆腐的心理贪图你的钱包。

大家不要听说机器学习需要高深的数学基础吓跑了，并不是说数学不重要，而是机器学习百分之 80 的数学，你都在大一或者高中都了解过了，你会求导就会了一大半。培训班很机械地搬出一些机器学习数学基础，概率论，线代，微积分一通乱讲，毫无必要。

### 第一阶段，原理入门

目标是搞清楚机器学习的基本概念和基本的算法原理。这个阶段的正反馈来自于新知识的获取，原理的理解。不要好高骛远。下面介绍几种入门方法，分别对应看书入门党，看视频入门党，有一些精选的优质资源推荐给初学者。推荐的资源，周志华《机器学习》，李航《统计学习方法》 Peter Harrington 《机器学习实战》吴恩达 Coursra 机器学习公开课

首先看书入门党，周志华和李航老师的西瓜书和统计学习方法都可以，可以快速地看完前几章，不要具体到算法，如果你愿意，看完逻辑回归就可以了，首先明白机器学习问题的定义，其次明白几个关键的名词，训练验证测试，偏差方差，样本，特征，标签。然后去看什么是监督学习什么是无监督学习，大概了解了这些之后，再到具体的算法。再推荐一本书《机器学习实战》绿皮书，这些书的特点就是原理讲的很明白，《机器学习实战》所有的算法都用代码实现了一遍，逻辑清晰很好理解，比那些用 sklaern 的书强一万倍。

看视频入门党，推荐吴恩达 Coursera 上的《机器学习》，吴恩达老师设计的课程已经非常适合入门了，侧重原理，逻辑清楚，机器学习的细节也面面俱到。

经过上述阶段，你大概对机器学习要解决的问题，使用的方法和适用场景都有所了解了，这时候，你大概对算法的原理也都八九不离十，但是学习原理总是枯燥的，不过一定要坚持下来，千万不要在这个阶段满足于调包。

### 第二阶段：在编程中理解原理

目标是能够自己动手实现算法的细节而不是用 sklearn 去调包。正反馈是自己动手从头正确实现机器学习算法。 推荐资源 Peter Harrington 《机器学习实战》吴恩达 Coursra 机器学习公开课编程作业。

这里推荐吴恩达老师机器学习课程的作业，不需要把每个算法都实现一遍，但是要在实践中去理解机器学习的基本算法套路，比如梯度下降是怎么做的，链式法则怎么用程序表达。还有就是《机器学习实战》的配套代码，这本书的最大好处是让你能够用最基本的 python 语法，从底层上让你构建代码，实现我们常说的比如邮件过滤，数据分类的应用。

很多时候你要写最基本的代码和结构去做这些工作，而不是像 sklearn 去调用 fit 和 predit，你能实现算法的底层原理，知道决策树的分割增益计算如何写代码，梯度下降如何写代码，知道机器学习是如何从 0 到 1 实现的。

不过这本书比较老旧了，重点也不是讲解理论方面的东西，可以当成第二个阶段的教材，和第一阶段互补。

另外一个是词向量 GloVe 的代码，为什么推荐 GloVe 的代码，他是一个用纯 c 语言写的机器学习做矩阵分解来求解词向量的程序，包含实现随机梯度下降，损失函数定义，数据并行处理等基本的要素，是麻雀虽小，五脏俱全，代码逻辑清晰，涉及到机器学习的方方面面，而且，毫无调包，代码量不大，很容易看懂。

stanfordnlp/GloVe

github.com/stanfordnlp/GloVe

### 第三阶段，实战应用

目标是把机器学习应用到实际问题中，加深对算法的理解。正反馈来自于使用机器学习工具来解决实际问题。推荐资源 Kaggle。

这时候，你对机器学习的原理，实现都有了解了，但是机器学习毕竟是一门应用的科学，我们通过在实战中学习机器学习。所以这个阶段非常适合打比赛。这里比较推荐 Kaggle 平台，不推荐国内的竞赛平台，除非你想给自己添堵，被排行榜上各种骚操作吓呆。至于怎么玩 kaggle，推荐 kaggle kernel 上的开源讨论，以及一些比较好的 Grand Master 的分享。如果能翻墙的话，可以看看这些：

### 第四阶段，精通和创新

这个阶段靠后期大家慢慢积累了，如果你是读硕博的话肯定有自己的研究方向。这个阶段应该也不需要什么推荐了，祝各位能够在自己专注的领域有所突破

（下面是另一个深入的答案，总结：需要扎实的数学和计算机基础）

我要翻译一把[quora](https://www.zhihu.com/search?q=quora&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357})了，再加点我的理解，我相信会是一个好答案，链接我都放到一起了，没插入到正文中，要求其实比较高了，我觉得我自己都差很远很远~~~我尽量持续更新翻译质量以及自己理解

> \1. **Python/C++/R/Java** - you will probably want to learn all of these languages at some point if you want a job in machine-learning. Python's Numpy and Scipy [libraries](https://www.zhihu.com/search?q=libraries&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}) [2] are awesome because they have similar functionality to MATLAB, but can be easily integrated into a web service and also used in Hadoop (see below). C++ will be needed to speed code up. R [3] is great for statistics and plots, and Hadoop [4] is written in Java, so you may need to implement mappers and reducers in Java (although you could use a scripting language via Hadoop streaming [5])

首先，你要熟悉这四种语言。Python 因为开源的库比较多，可以看看 Numpy 和 Scipy 这两个库，这两个都可以很好的融入网站开发以及 Hadoop。C++可以让你的代码跑的更快，R 则是一个很好地统计工具。而你想很好地使用 Hadoop 你也必须懂得 java，以及如何实现[map reduce](https://www.zhihu.com/search?q=map+reduce&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357})

> \2. **Probability and Statistics**: A good portion of learning algorithms are based on this theory. Naive Bayes [6], Gaussian Mixture Models [7], Hidden Markov Models [8], to name a few. You need to have a firm understanding of Probability and Stats to understand these models. Go nuts and study measure theory [9]. Use statistics as an model evaluation metric: [confusion matrices](https://www.zhihu.com/search?q=confusion+matrices&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}), receiver-operator curves, p-values, etc.

我推荐统计学习方法 李航写的，这算的上我 mentor 的 mentor 了。理解一些概率的理论，比如贝叶斯，SVM，CRF，HMM，决策树，AdaBoost，逻辑斯蒂回归，然后再稍微看看怎么做 evaluation 比如 P R F。也可以再看看假设检验的一些东西。

> \3. **Applied Math + Algorithms**: For discriminate models like SVMs [10], you need to have a firm understanding of algorithm theory. Even though you will probably never need to implement an SVM from scratch, it helps to understand how the algorithm works. You will need to understand subjects like convex optimization [11], gradient decent [12], [quadratic programming](https://www.zhihu.com/search?q=quadratic+programming&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}) [13], lagrange [14], partial differential equations [15], etc. Get used to looking at summations [16].

机器学习毕竟是需要极强极强数学基础的。我希望开始可以深入的了解一些算法的本质，SVM 是个很好的下手点。可以从此入手，看看拉格朗日，凸优化都是些什么

> \4. **Distributed Computing**: Most machine learning jobs require working with large data sets these days (see Data Science) [17]. You cannot process this data on a single machine, you will have to distribute it across an entire cluster. Projects like Apache Hadoop [4] and cloud services like Amazon's EC2 [18] makes this very easy and cost-effective. Although Hadoop abstracts away a lot of the hard-core, distributed computing problems, you still need to have a firm understanding of [map-reduce](https://www.zhihu.com/search?q=map-reduce&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}) [22], distribute-file systems [19], etc. You will most likely want to check out Apache Mahout [20] and Apache Whirr [21].

熟悉分布计算，机器学习当今必须是多台机器跑大数据，要不然没啥意义。请熟悉 Hadoop，这对找工作有很大很大的意义。百度等公司都需要 hadoop 基础。

> \5. **Expertise in Unix Tools**: Unless you are very fortunate, you are going to need to modify the format of your data sets so they can be loaded into R,Hadoop,HBase [23],etc. You can use a scripting language like python (using re) to do this but the best approach is probably just master all of the awesome unix tools that were designed for this: cat [24], grep [25], find [26], [awk](https://www.zhihu.com/search?q=awk&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}) [27], sed [28], sort [29], cut [30], tr [31], and many more. Since all of the processing will most likely be on linux-based machine (Hadoop doesnt run on Window I believe), you will have access to these tools. You should learn to love them and use them as much as possible. They certainly have made my life a lot easier. A great example can be found here [1].

熟悉 Unix 的 Tool 以及命令。百度等公司都是依靠 Linux 工作的，可能现在依靠 Windows 的 Service 公司已经比较少了。所以怎么也要熟悉 Unix 操作系统的这些指令吧。我记得有个百度的面试题就是问文件复制的事情。

> \6. **Become familiar with the Hadoop sub-projects**: HBase, Zookeeper [32], Hive [33], Mahout, etc. These projects can help you store/access your data, and they scale.

机器学习终究和大数据息息相关，所以 Hadoop 的子项目要关注，比如 HBase Zookeeper Hive 等等

> \7. **Learn about advanced signal processing techniques**: feature extraction is one of the most important parts of machine-learning. If your features suck, no matter which algorithm you choose, your going to see horrible performance. Depending on the type of problem you are trying to solve, you may be able to utilize really cool advance signal processing algorithms like: [wavelets](https://www.zhihu.com/search?q=wavelets&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}) [42], shearlets [43], curvelets [44], contourlets [45], bandlets [46]. Learn about time-frequency analysis [47], and try to apply it to your problems. If you have not read about Fourier Analysis[48] and Convolution[49], you will need to learn about this [stuff](https://www.zhihu.com/search?q=stuff&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}) too. The ladder is signal processing 101 stuff though.

这里主要是在讲特征的提取问题。无论是分类（classification）还是回归（regression）问题，都要解决特征选择和抽取（extraction）的问题。他给出了一些基础的特征抽取的工具如小波等，同时说需要掌握[傅里叶分析](https://www.zhihu.com/search?q=傅里叶分析&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357})和卷积等等。这部分我不大了解，大概就是说信号处理你要懂，比如傅里叶这些。。。

> Finally, practice and read as much as you can. In your free time, read papers like Google Map-Reduce [34], Google File System [35], Google Big Table [36], The Unreasonable Effectiveness of Data [37],etc There are great free machine learning books online and you should read those also. [38][39][40]. Here is an awesome course I found and re-posted on github [41]. Instead of using open source packages, code up your own, and compare the results. If you can code an SVM from scratch, you will understand the concept of support [vectors](https://www.zhihu.com/search?q=vectors&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}), gamma, cost, [hyperplanes](https://www.zhihu.com/search?q=hyperplanes&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A22465357}), etc. It's easy to just load some data up and start training, the hard part is making sense of it all.

总之机器学习如果想要入门分为两方面：

一方面是去看算法，需要极强的数理基础（真的是极强的），从 SVM 入手，一点点理解。

另一方面是学工具，比如分布式的一些工具以及 Unix~
